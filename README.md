# POC Kafka

ServiÃ§os desenvolvidos para aplicar os conceitos do Apache Kafka.

- `api`: Utilizado como [_producer_](https://docs.confluent.io/platform/current/clients/producer.html) do projeto.
- `worker`: Utilizado como [_consumer_](https://docs.confluent.io/platform/current/clients/consumer.html) do projeto.

---

## DependÃªncias

- NecessÃ¡rio ter o `docker-compose -v` funcionando corretamente.

## Passo a passo

- Clone o repositÃ³rio (`$ git clone git@github.com:gustavo-flor/poc-kafka.git`);

- Acesse a pasta clonada (`$ cd poc-kafka`) ðŸ—ƒï¸;

- Execute o `docker-compose up -d` para subir o broker do Kafka com Zookeeper;

- Acesse o subprojeto `api` e execute o comando (`$ ./mvnw spring-boot:run`), **necessÃ¡rio ter a porta 8080 disponÃ­vel**;

- Acesse o subprojeto `worker` e execute o comando (`$ ./mvnw spring-boot:run`); 

- Estamos prontos para utilizar a aplicaÃ§Ã£o ðŸŽ‰.

## Endpoints

> POST | http://localhost:8080/login

````json5
{
    "name": "String"
}
````

Este endpoint pode retornar randomicamente um dos dois status `200` ou `400`, cada um deles gerando uma mensagem diferente para o Kafka respectivamente nos tÃ³picos `poc-kafka_login-success` e `poc-kafka_login-failure`.

---

> POST | http://localhost:8080/logout

Este endpoint retorna status `200` e gera uma mensagem para o Kafka no tÃ³pico `poc-kafka_logout`.

## Chegamos ao fim ðŸŽ‰

Fique a vontade para contribuir com essa POC implementando novos conceitos, atÃ© maisss!!
